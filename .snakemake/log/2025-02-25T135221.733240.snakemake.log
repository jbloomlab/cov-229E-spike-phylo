Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 16
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job stats:
job                                count
-------------------------------  -------
align_protein_sequences                1
all                                    1
ancestral_tree_sequences               1
calculate_variation                    1
check_number_ORFs_found                1
colors                                 1
create_codon_alignment                 1
download_and_process_accessions        1
edit_codon_fasta_headers               1
edit_protein_fasta_headers             1
export_tree                            1
get_codon_sequences                    1
get_protein_sequences                  1
refine_tree_sequences                  1
root_and_remove_outgroup               1
strip_codon_alignment_gaps             1
strip_protein_alignment_gaps           1
traits_tree_sequences                  1
translate_tree_sequences               1
tree_sequences                         1
total                                 20

Select jobs to execute...

[Tue Feb 25 13:52:26 2025]
rule download_and_process_accessions:
    input: Configure/Input_Data/229E_full_accession_list.txt
    output: Results/spike/nucleotide.fasta, Results/spike/metadata.tsv
    log: Results/Logs/spike/download_and_process_accessions.txt
    jobid: 2
    reason: Missing output files: Results/spike/metadata.tsv, Results/spike/nucleotide.fasta
    wildcards: gene=spike
    resources: tmpdir=/loc/scratch/11396368

[Tue Feb 25 13:52:29 2025]
Error in rule download_and_process_accessions:
    jobid: 2
    input: Configure/Input_Data/229E_full_accession_list.txt
    output: Results/spike/nucleotide.fasta, Results/spike/metadata.tsv
    log: Results/Logs/spike/download_and_process_accessions.txt (check log file(s) for error details)
    conda-env: /fh/fast/bloom_j/computational_notebooks/sharari/2025/HcoV_229E_phylo_analysis/.snakemake/conda/97c12c1be2db4304555330299cbcc68d_

RuleException:
CalledProcessError in file /fh/fast/bloom_j/computational_notebooks/sharari/2025/HcoV_229E_phylo_analysis/Rules/download_and_process_accessions.smk, line 40:
Command 'set -euo pipefail;  /home/sharari/miniforge3/envs/evo_jump/bin/python3.11 /fh/fast/bloom_j/computational_notebooks/sharari/2025/HcoV_229E_phylo_analysis/.snakemake/scripts/tmp2yhftljg.download_NCBI_sequences.py' returned non-zero exit status 1.
  File "/fh/fast/bloom_j/computational_notebooks/sharari/2025/HcoV_229E_phylo_analysis/Rules/download_and_process_accessions.smk", line 40, in __rule_download_and_process_accessions
  File "/home/sharari/miniforge3/envs/evo_jump/lib/python3.11/concurrent/futures/thread.py", line 58, in run
Removing output files of failed job download_and_process_accessions since they might be corrupted:
Results/spike/nucleotide.fasta, Results/spike/metadata.tsv
Trying to restart job 2.
Select jobs to execute...

[Tue Feb 25 13:52:29 2025]
rule download_and_process_accessions:
    input: Configure/Input_Data/229E_full_accession_list.txt
    output: Results/spike/nucleotide.fasta, Results/spike/metadata.tsv
    log: Results/Logs/spike/download_and_process_accessions.txt
    jobid: 2
    reason: Missing output files: Results/spike/metadata.tsv, Results/spike/nucleotide.fasta
    wildcards: gene=spike
    resources: tmpdir=/loc/scratch/11396368

[Tue Feb 25 13:52:30 2025]
Error in rule download_and_process_accessions:
    jobid: 2
    input: Configure/Input_Data/229E_full_accession_list.txt
    output: Results/spike/nucleotide.fasta, Results/spike/metadata.tsv
    log: Results/Logs/spike/download_and_process_accessions.txt (check log file(s) for error details)
    conda-env: /fh/fast/bloom_j/computational_notebooks/sharari/2025/HcoV_229E_phylo_analysis/.snakemake/conda/97c12c1be2db4304555330299cbcc68d_

RuleException:
CalledProcessError in file /fh/fast/bloom_j/computational_notebooks/sharari/2025/HcoV_229E_phylo_analysis/Rules/download_and_process_accessions.smk, line 40:
Command 'set -euo pipefail;  /home/sharari/miniforge3/envs/evo_jump/bin/python3.11 /fh/fast/bloom_j/computational_notebooks/sharari/2025/HcoV_229E_phylo_analysis/.snakemake/scripts/tmpo1e9gfmf.download_NCBI_sequences.py' returned non-zero exit status 1.
  File "/fh/fast/bloom_j/computational_notebooks/sharari/2025/HcoV_229E_phylo_analysis/Rules/download_and_process_accessions.smk", line 40, in __rule_download_and_process_accessions
  File "/home/sharari/miniforge3/envs/evo_jump/lib/python3.11/concurrent/futures/thread.py", line 58, in run
Removing output files of failed job download_and_process_accessions since they might be corrupted:
Results/spike/nucleotide.fasta, Results/spike/metadata.tsv
Trying to restart job 2.
Select jobs to execute...

[Tue Feb 25 13:52:30 2025]
rule download_and_process_accessions:
    input: Configure/Input_Data/229E_full_accession_list.txt
    output: Results/spike/nucleotide.fasta, Results/spike/metadata.tsv
    log: Results/Logs/spike/download_and_process_accessions.txt
    jobid: 2
    reason: Missing output files: Results/spike/metadata.tsv, Results/spike/nucleotide.fasta
    wildcards: gene=spike
    resources: tmpdir=/loc/scratch/11396368

[Tue Feb 25 13:52:31 2025]
Error in rule download_and_process_accessions:
    jobid: 2
    input: Configure/Input_Data/229E_full_accession_list.txt
    output: Results/spike/nucleotide.fasta, Results/spike/metadata.tsv
    log: Results/Logs/spike/download_and_process_accessions.txt (check log file(s) for error details)
    conda-env: /fh/fast/bloom_j/computational_notebooks/sharari/2025/HcoV_229E_phylo_analysis/.snakemake/conda/97c12c1be2db4304555330299cbcc68d_

RuleException:
CalledProcessError in file /fh/fast/bloom_j/computational_notebooks/sharari/2025/HcoV_229E_phylo_analysis/Rules/download_and_process_accessions.smk, line 40:
Command 'set -euo pipefail;  /home/sharari/miniforge3/envs/evo_jump/bin/python3.11 /fh/fast/bloom_j/computational_notebooks/sharari/2025/HcoV_229E_phylo_analysis/.snakemake/scripts/tmphsg00ez_.download_NCBI_sequences.py' returned non-zero exit status 1.
  File "/fh/fast/bloom_j/computational_notebooks/sharari/2025/HcoV_229E_phylo_analysis/Rules/download_and_process_accessions.smk", line 40, in __rule_download_and_process_accessions
  File "/home/sharari/miniforge3/envs/evo_jump/lib/python3.11/concurrent/futures/thread.py", line 58, in run
Removing output files of failed job download_and_process_accessions since they might be corrupted:
Results/spike/nucleotide.fasta, Results/spike/metadata.tsv
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2025-02-25T135221.733240.snakemake.log
